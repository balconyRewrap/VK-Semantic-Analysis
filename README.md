# Программа по определению эмоциональной окраски постов и комментариев пользователей в социальной сети ВКонтакте на основе нейронной сети, написанной на языке программирования Python

## Нейронная сеть для анализа Вконтакте

### ``Зависимости для Python для обучения нейросети:``
**Библиотеки:**
1) keras
2) numpy
3) sklearn
4) pickle
5) scipy
6) tensorflow
7) nltk
8) h5py

**Команда для установки:**
```pip install keras numpy scikit-learn pickle scipy tensorflow nltk h5py```

### ``Используемые Датасеты для обучения нейросети```
**Используемые по прямому назначению:**
1) [RuTweetCorp (Rubtsova, 2013)](http://study.mokoron.com/)
~~ХА-ХА, сайт не хоститься уже года 3, найти сами датасеты можно только чудом в глубинах сети~~
2) [RuReviews (Smetanin and Komarov, 2019)](https://ieeexplore.ieee.org/document/8807792)
3) [Russian Language Toxic Comments (2ch.hk и Pikabu.ru)](https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments)
4) [PolSentiLex 2015 и 2016](https://linis-crowd.org/)

**Датасеты для аугментации основных:**
1) [Словарь матерных слов](https://mat2.slovaronline.com/)
Сам датасет не предоставляет, пришлось парсить
2) [Список русских матерных слов для бана](https://github.com/bars38/Russian_ban_words)

### ``Зависимости для тренировки и использования нейросети вообще:``
**Если хотите тренировать только на процессоре:**
1) [HDF5](https://www.hdfgroup.org/downloads/hdf5)

**Если хотите тренировать только на или и на видеокарте:**
1) cuda
2) cudnn


### ``Цель проекта: ``

Разработать программу, которая может анализировать эмоциональную окраску постов и комментариев во Вконтакте.
### `` Задачи проекта: ``

1) Написать алгоритм (***веб-парсер***), позволяющий собирать необходимую информацию из социальной сети Вконтакте (сообщества, страница пользователя, перечень сообществ или групп и так далее);
2) Создать алгоритм на основе нейронной сети для анализа постов и комментариев.
3) Создать набор данных в формате, который может использоваться для обучения нейронной сети;
4) Написать алгоритм, позволяющий структурировать входные данные нужным образом для обработки их нейронной сетью;
5) Обучить нейронную сеть на основе созданного набора данных для классификации постов и комментариев по эмоциональной окраске (например, на позитивную и негативную);
6) Написать алгоритм, позволяющий представить результат в подходящей для пользователя форме;
7) Написать программный интерфейс приложения (***API***) для интеграции программы с другими.

### ``Теоретическая справка:``

1) **Нейронная сеть** — это алгоритм машинного обучения, который моделирует функционирование человеческого мозга и позволяет компьютеру обучаться на основе большого количества данных.
Она состоит из большого количества взаимосвязанных элементов, называемых нейронами, которые обрабатывают информацию, передавая ее друг другу через соединения, называемые синапсами. Нейроны сети работают вместе, чтобы решать задачи обработки информации, например, классификацию изображений, распознавание речи, прогнозирование временных рядов и т.д.
Обучение нейронной сети происходит на основе обратного распространения ошибки, когда сеть анализирует набор обучающих данных и пытается улучшить свою работу, подстраивая параметры своих нейронов для достижения наилучшего результата.
2) **Веб-парсер** — это программа, которая извлекает данные с веб-страниц и анализирует их для последующей обработки или использования. Веб-парсеры могут быть использованы для сбора информации о товарах, ценах, новостях и других данных из различных источников в интернете.

### ``Существующие наработки по схожей теме:``

1) [Twitter semantic analysis от программиста под никнеймом Cercosa](https://github.com/Cercosa/Twitter_semantic_analysis)
2) [SemanticAnalysis от программиста под никнеймом kokwai48699](https://github.com/kokwai4869/SemanticAnalysis)
3) [semanticAnalysis от программиста под никнеймом hudongyue1](https://github.com/hudongyue1/semanticAnalysis)
4) [SemanticAnalysis от программиста под никнеймом Jared-Hall](https://github.com/Jared-Hall/SemanticAnalysis)
5) [SAoT от программиста под никнеймом zackotterstrom](https://github.com/zackotterstrom/SAoT)

### ``Преимущества нашего проекта над представленными аналогами:``

1) Создан для работы с ***Русским языком***;
2) Рассчитан на работу с социальной сетью ***Вконтакте***;
3) Может сам получать необходимую информацию из источников без необходимости вносить все данные вручную;
4) Прост в освоении и использовании;
5) Имеет механизм интеграции (***API***) с другими программными обеспечениями.

### ``Итоговым результатом нашего проекта является:``

**Программное обеспечение**, с помощью которого пользователи могут получить удобный и быстрый способ анализировать эмоциональную окраску своих постов и комментариев в социальной сети ВКонтакте, например, чтобы определить, как их мнение будет воспринято другими пользователями. Также это может быть полезно для маркетинговых исследований, анализа общественного мнения и других приложений, связанных с анализом текстов в социальных медиа.

### ``Возможные проблемы с которыми мы можем столкнуться по ходу проекта: ``

1) Необходимость в большом объеме данных для обучения нейронной сети. Чтобы создать точную модель, необходимо обучить нейронную сеть на большом количестве текстов с известной эмоциональной окраской. Если доступных данных будет недостаточно, то это может снизить точность и эффективность модели.
2) Необходимость в эффективном алгоритме предобработки данных. Прежде чем подавать данные на вход нейронной сети, необходимо их предобработать, чтобы сделать тексты более чистыми и структурированными. Неэффективный алгоритм предобработки может снизить качество модели.
3) Проблемы с определением эмоциональной окраски. Эмоциональная окраска может быть субъективной и зависеть от контекста, что может затруднить определение ее точной эмоциональной окраски. Это может снизить точность модели.
### ``Области знаний, которые затрагиваются в проекте:``

1) **Обработка естественного языка** (***Natural Language Processing, NLP***) для анализа текстовых данных.
2) Машинное обучение, в частности, **глубокое обучение** (***Deep Learning***), для создания нейронной сети, которая будет определять эмоциональную окраску текстов.
---
### ``Требуемое аппаратное обеспечение для проекта:``
1) HP Pavilion 15:
    1. Процессор — Intel Core I7-8550U 1.80Ghz
    2. Видеокарта — Nvidia GeForce GTX 1050

2) Asus Vivobook Pro 15:
    1. Процессор — Intel Core I5-11300H 3.10Ghz
    2. Видеокарта — Nvidia GeForce GTX 1650

### `` Используемые операционные системы для проекта: ``
[LINUX MINT 21.1](https://www.linuxmint.com/)

### `` Используемый Язык Программирования: ``
[Python](https://www.python.org/)
### ``Обоснование выбора Языка Программирования, а именно Python:``
Python используется в нашем проекте, так как он обладает всеми необходимыми инструментами для работы с естественным языком и глубоким обучением, а также может использоваться для создания веб-приложений и других интерфейсов. Python имеет все необходимые библиотеки, которые подходят для реализации нашего проекта, например, requests и BeautifulSoup4 для веб-парсинга.  
Также Python имеет простой и понятный синтаксис, что делает его легко читаемым и понятным для всех членов в команды вне зависимости от их уровня.  
Python также является кросс-платформенным языком, что означает, что приложения, написанные на Python, могут быть запущены на различных операционных системах без изменений в коде, что позволит легко портировать код на другие системы.

### ``Используемое программное обеспечение:``
1) **PyCharm** — это интегрированная среда разработки (***IDE***) для языка программирования Python, разработанная компанией JetBrains. PyCharm обладает широкими возможностями для разработки, включая автодополнение кода, отладку, поддержку различных фреймворков и тестирование.
2) **Pip** — это инструмент командной строки для управления пакетами в Python. С помощью pip вы можете устанавливать, обновлять и удалять пакеты Python из централизованного репозитория PyPI (Python Package Index). Он также позволяет установить пакеты из других источников, таких как Git или SVN. Pip также обладает возможностью установки зависимостей, что делает его необходимым инструментом для управления пакетами в Python.

### ``Предполагаемые библиотеки, используемые для реализации проекта:``
1) **Requests** — библиотека для работы с HTTP-запросами. Она позволяет получать данные с веб-страниц, отправлять данные на сервер и авторизоваться на сайтах.
2) **Beautiful Soup 4** — библиотека для парсинга HTML и XML документов. Она позволяет извлекать информацию из HTML-страниц, например, тексты статей, заголовки и ссылки.
3) **NumPy** — библиотека для работы с многомерными массивами и математическими функциями.
4) **Pandas** — библиотека для работы с данными, включая чтение и запись данных в различных форматах, манипуляции с данными и агрегирование данных.
5) **Scikit-learn** — библиотека для машинного обучения, включающая алгоритмы классификации, регрессии, кластеризации, выбора моделей и многие другие.
6) **TensorFlow** — библиотека для разработки и обучения нейронных сетей.
7) **Keras** — высокоуровневый API для работы с нейронными сетями, основанный на TensorFlow.
8) **NLTK (Natural Language Toolkit)** — библиотека для работы с естественным языком, включающая алгоритмы токенизации, стемминга, лемматизации и другие.
9) **Seaborn** — библиотека для визуализации данных, основанная на Matplotlib, но с более простым и красивым интерфейсом.
10) **SpaCy** — библиотека для обработки естественного языка на Python. Она используется для выполнения различных задач в области обработки естественного языка, таких как токенизация, лемматизация, извлечение именованных сущностей и анализ зависимостей.
---
### ``Роли в команде:``
1) **Рогачев Михаил Валерьевич** — Project Manager, инженер по машинному обучение, разработчик Python
2) **Капленко Артём Алексеевич** —  Аналитик данных, разработчик Python
3) **Хромов Виктор Владимирович** — Тестировщик
---
### ``Roadmap проекта:``
#### 3-14 Недели:
- [x] 1) Сбор тестовых данных — 3-4 недели — **Капленко**;  
- [x] 2) Алгоритм, позволяющий структурировать входные данные нужным образом для обработки их нейронной сетью - 4-5 недели — **Рогачев**;
- [x] 3) Разработка первой версии нейронной сети — 5-6 недели — **Рогачев**;
- [x] 4) Сбор и предварительная обработка данных для обучения нейронной сети, включая посты и комментарии пользователей ВКонтакте — 6-8 недели — **Капленко**;
- [x] 5) Обучение нейронной сети на первоначальных собранных данных — 8-13 недели — **Рогачев/Капленко**;
- [ ] 6) Тестирование нейронной сети — 12-14 недели — **Хромов**.
#### Второй курс:
- [ ] 1) Оптимизация нейронной сети;
- [ ] 2) Сбор и обработка дополнительных данных при необходимости;
- [ ] 3) Обучение нейронной сети на дополнительных данных;
- [ ] 4) Разработка первоначального механизма для получения данных из социальной сети Вконтакте;
- [ ] 5) Тестирование механизма;
- [ ] 6) Разработка программного обеспечения на Python для использования нейронной сети в реальном времени;
- [ ] 7) Тестирование и отладка программного обеспечения;
- [ ] 8) Выпуск программного обеспечения.
